{
 "cells": [
  {
   "cell_type": "raw",
   "id": "33dd6c4c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Project Code\"\n",
    "subtitle: Sneaky Pythons\n",
    "author: Alissa Chu, Adam Ruzumna, and Judd Moss \n",
    "date: 02/27/2023\n",
    "number-sections: true\n",
    "abstract: _This file contains the code for the project on <>, as part of the STAT303-2 course in Winter 2023_.\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    self-contained: true\n",
    "    font-size: 100%\n",
    "    toc-depth: 4\n",
    "    mainfont: serif\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e7536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba5ee91",
   "metadata": {},
   "source": [
    "## Length of the code {-}\n",
    "No restriction\n",
    "\n",
    "**Delete this section from the report, when using this template.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ea9bb",
   "metadata": {},
   "source": [
    "## Data quality check / cleaning / preparation \n",
    "\n",
    "Put code with comments. The comments should explain the code such that it can be easily understood. You may put text *(in a markdown cell)* before a large chunk of code to explain the overall purpose of the code, if it is not intuitive. **Put the name of the person / persons who contributed to each code chunk / set of code chunks.** An example is given below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db149d8b",
   "metadata": {},
   "source": [
    "### Data quality check\n",
    "*By Elton John*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc82e7f",
   "metadata": {},
   "source": [
    "The code below visualizes the distribution of all the variables in the dataset, and their association with the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5955618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...Distribution of continuous variables...#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8faafdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...Distribution of categorical variables...#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e389f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...Association of the response with the predictors...#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1561829",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "*By Xena Valenzuela*\n",
    "\n",
    "From the data quality check we realized that:\n",
    "\n",
    "1. Some of the columns that should have contained only numeric values, specifically <>, <>, and <> have special characters such as \\*, #, %. We'll remove these characters, and convert the datatype of these columns to numeric.\n",
    "\n",
    "2. Some of the columns have more than 60% missing values, and it is very difficult to impute their values, as the values seem to be missing at random with negligible association with other predictors. We'll remove such columns from the data.\n",
    "\n",
    "3. The column `number_of_bedrooms` has some unreasonably high values such as 15. As our data consist of single-family homes in Evanston, we suspect that any value greater than 5 may be incorrect. We'll replace all values that are greater than 5 with an estimate obtained using the $K$-nearest neighbor approach.\n",
    "\n",
    "4. The columns `house_price` has some unreasonably high values. We'll tag all values greater than 1 billion dollars as \"potentially incorrect observation\", to see if they distort our prediction / inference later on.\n",
    "\n",
    "The code below implements the above cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f73626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...Code with comments...#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b91a14e",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "*By Adam Ruzumna and Judd Moss*\n",
    "\n",
    "The following data preparation steps helped us to prepare our data for implementing various modeling / validation techniques:\n",
    "\n",
    "1. Since we need to predict house price, we derived some new predictors *(from existing predictors)* that intuitively seem to be helpuful to predict house price. \n",
    "\n",
    "2. We have shuffled the dataset to prepare it for K-fold cross validation.\n",
    "\n",
    "3. We have created a standardized version of the dataset, as we will use it to develop Lasso / Ridge regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b2b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######---------------Creating new predictors----------------#########\n",
    "\n",
    "#Creating number of bedrooms per unit floor area\n",
    "\n",
    "#Creating ratio of bathrooms to bedrooms\n",
    "\n",
    "#Creating ratio of carpet area to floor area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e04063",
   "metadata": {},
   "outputs": [],
   "source": [
    "######-----------Shuffling the dataset for K-fold------------#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cecc4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "######-----Standardizing the dataset for Lasso / Ridge-------#########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa9f72b",
   "metadata": {},
   "source": [
    "- Adding in continents to be a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c0a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in continents to be a categorical variable\n",
    "continents_df = pd.read_csv('gdp_lifeExpectancy.csv')\n",
    "continents = continents_df[['country', 'continent']]\n",
    "continents.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7787aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, continents, on='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad3666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb11c9b",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd74a9",
   "metadata": {},
   "source": [
    "Put code with comments. The comments should explain the code such that it can be easily understood. You may put text *(in a markdown cell)* before a large chunk of code to explain the overall purpose of the code, if it is not intuitive. **Put the name of the person / persons who contributed to each code chunk / set of code chunks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a4eb91",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Exploting different distributions of life expectancy by continent - Judd Moss\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sns\u001b[38;5;241m.\u001b[39mdisplot(data \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m, x \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlife_expectancy\u001b[39m\u001b[38;5;124m'\u001b[39m,kind \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkde\u001b[39m\u001b[38;5;124m'\u001b[39m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontinent\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mset_titles(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLife Expectancy Distribution by Continent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# Exploring different distributions of life expectancy by continent - Judd Moss\n",
    "sns.displot(data = train, x = 'life_expectancy',kind = 'kde', hue='continent').set_titles(\"Life Expectancy Distribution by Continent\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f679eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the correlation with life_expectancy and the potential predictors - Judd Moss\n",
    "sns.set(rc={'figure.figsize':(12,10)})\n",
    "sns.heatmap(train.corr(), cmap='tab10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef0e074",
   "metadata": {},
   "source": [
    "- The variable most correlated with life expectancy was `income_composition_of_resources` so we wanted to check its distribution since it was on a 0-1 scale to see where most countries fell on the scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab566567",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# check scatterplot of income_composition_of_resources and life expectancy - Judd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ax \u001b[38;5;241m=\u001b[39m sns\u001b[38;5;241m.\u001b[39mscatterplot(data \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m, x \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincome_composition_of_resources\u001b[39m\u001b[38;5;124m'\u001b[39m,y \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlife_expectancy\u001b[39m\u001b[38;5;124m'\u001b[39m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontinent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLife Expectancy by Continent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# check scatterplot of income_composition_of_resources and life expectancy - Judd\n",
    "ax = sns.scatterplot(data = train, x = 'income_composition_of_resources',y = 'life_expectancy', hue='continent')\n",
    "ax.set_title(\"Life Expectancy by Continent\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4223c843",
   "metadata": {},
   "source": [
    "- `income_composition_of_resources` measures on a scale of 0 to 1, a countries ability to utilize its resources. We can see many of the countries with values of `income_composition_of_resources` have a higher life expectancy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab331a",
   "metadata": {},
   "source": [
    "## Developing the model\n",
    "*By Judd Moss and Alissa Chu*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ec4c9",
   "metadata": {},
   "source": [
    "Put code with comments. The comments should explain the code such that it can be easily understood. You may put text *(in a markdown cell)* before a large chunk of code to explain the overall purpose of the code, if it is not intuitive. **Put the name of the person / persons who contributed to each code chunk / set of code chunks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5528b775",
   "metadata": {},
   "source": [
    "**Addressing Multicollinearity**\n",
    "- In the following code chunk, we tested the multicollinearity of the predictors that could be used in our regression model. Since many of the healthcare variables were related we suspected the predictors would exhibit some collinearity. To check this, we computed their VIF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a25e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictors VIF will be caluclated for:\n",
    "\n",
    "X = train[['adult_mortality','measles', 'under_five_deaths', 'polio', 'diphtheria', 'hiv_aids', \n",
    "           'gdp_per_capita', 'thinness_1_19_years', 'thinness_5_9_years',\n",
    "           'income_composition_of_resources', 'schooling']]\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# add constant column\n",
    "X = add_constant(X)\n",
    "# create empty dataframe to input VIF values\n",
    "vif_data=pd.DataFrame()\n",
    "# create row for each predictor in X\n",
    "vif_data['predictor'] = X.columns\n",
    "\n",
    "# for loop to fill in VIF values \n",
    "for i in range(len(X.columns)):\n",
    "    vif_data.loc[i,'VIF'] = variance_inflation_factor(X.values,i)\n",
    "    \n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a534b7",
   "metadata": {},
   "source": [
    "- We then checked which variables were most correlated with `life_expectancy` to decide which variables with high VIF levels to remove. It appears `thinness_1_19_years`, `thinness_5_9_years`, `income_composition_of_resources`, and `schooling` exhibit multicollinearity. Based on their correlations with `life_expectancy`, we will remove `thinness_5_9_years` and `schooling` since they are less correlated with `life_expectancy`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e1e87d",
   "metadata": {},
   "source": [
    "**Model Selection**\n",
    "- We ran a forward stepwise selection algorithm to help determine which variables we should use in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1663d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe with all the predictors\n",
    "X = train[['adult_mortality', 'measles', 'under_five_deaths', 'polio', 'diphtheria', 'hiv_aids', 'gdp_per_capita', 'thinness_1_19_years', 'income_composition_of_resources']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6300c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to develop a model based on all predictors in predictor_subset\n",
    "def processSubset(predictor_subset):\n",
    "    # Fit model on feature_set and calculate R-squared\n",
    "    model = sm.ols('life_expectancy~' + '+'.join(predictor_subset),data = train).fit()\n",
    "    Rsquared = model.rsquared\n",
    "    return {\"model\":model, \"Rsquared\":Rsquared}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad5fb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find the best predictor out of p-k predictors and add it to the model containing the k predictors\n",
    "def forward(predictors):\n",
    "\n",
    "    # Pull out predictors we still need to process\n",
    "    remaining_predictors = [p for p in X.columns if p not in predictors]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for p in remaining_predictors:\n",
    "        results.append(processSubset(predictors+[p]))\n",
    "    \n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # Choose the model with the highest RSS\n",
    "    best_model = models.loc[models['Rsquared'].argmax()]\n",
    "\n",
    "    print(\"Processed \", models.shape[0], \"models on\", len(predictors)+1, \"predictors\")\n",
    "    \n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f87ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection():\n",
    "    models_best = pd.DataFrame(columns=[\"Rsquared\", \"model\"])\n",
    "\n",
    "    predictors = []\n",
    "\n",
    "    for i in range(1,len(X.columns)+1):    \n",
    "        models_best.loc[i] = forward(predictors)\n",
    "        predictors = list(models_best.loc[i][\"model\"].params.index[1:])\n",
    "\n",
    "    return models_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4d06d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_best = forward_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d402ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to assess which model is the best using AIC, BIC and adjusted R2\n",
    "def best_sub_plots():\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.rcParams.update({'font.size': 18, 'lines.markersize': 10})\n",
    "\n",
    "    # Set up a 2x2 grid so we can look at 4 plots at once\n",
    "    plt.subplot(2, 2, 1)\n",
    "\n",
    "    # We will now plot a red dot to indicate the model with the largest adjusted R^2 statistic.\n",
    "    # The argmax() function can be used to identify the location of the maximum point of a vector\n",
    "    plt.plot(models_best[\"Rsquared\"])\n",
    "    plt.xlabel('# Predictors')\n",
    "    plt.ylabel('Rsquared')\n",
    "\n",
    "    # We will now plot a red dot to indicate the model with the largest adjusted R^2 statistic.\n",
    "    # The argmax() function can be used to identify the location of the maximum point of a vector\n",
    "\n",
    "    rsquared_adj = models_best.apply(lambda row: row[1].rsquared_adj, axis=1)\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(rsquared_adj)\n",
    "    plt.plot(1+rsquared_adj.argmax(), rsquared_adj.max(), \"or\")\n",
    "    plt.xlabel('# Predictors')\n",
    "    plt.ylabel('adjusted rsquared')\n",
    "\n",
    "    # We'll do the same for AIC and BIC, this time looking for the models with the SMALLEST statistic\n",
    "    aic = models_best.apply(lambda row: row[1].aic, axis=1)\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(aic)\n",
    "    plt.plot(1+aic.argmin(), aic.min(), \"or\")\n",
    "    plt.xlabel('# Predictors')\n",
    "    plt.ylabel('AIC')\n",
    "\n",
    "    bic = models_best.apply(lambda row: row[1].bic, axis=1)\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(bic)\n",
    "    plt.plot(1+bic.argmin(), bic.min(), \"or\")\n",
    "    plt.xlabel('# Predictors')\n",
    "    plt.ylabel('BIC')\n",
    "best_sub_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02e8a35",
   "metadata": {},
   "source": [
    "**Result: Based on adjusted R2, AIC, and BIC, it appears the model with all 9 predictors is the best model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0b2ef8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6444e611",
   "metadata": {},
   "source": [
    "### Code fitting the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cae72f",
   "metadata": {},
   "source": [
    "Put the code(s) that fit the final model(s) in separate cell(s), i.e., the code with the `.ols()` or `.logit()` functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a185cb",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations to stakeholder(s)\n",
    "\n",
    "You may or may not have code to put in this section. Delete this section if it is irrelevant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
